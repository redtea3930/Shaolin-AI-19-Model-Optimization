{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Audit\n",
    "\n",
    "## Dataset\n",
    "\n",
    "You will examine the ProPublica COMPAS dataset, which consists of all criminal defendants who were subject to COMPAS screening in Broward County, Florida, during 2013 and 2014. For each defendant, various information fields (‘features’) were also gathered by ProPublica. Broadly, these fields are related to the defendant’s demographic information (e.g., gender and race), criminal history (e.g., the number of prior offenses) and administrative information about the case (e.g., the case number, arrest date, risk of recidivism predicted by the COMPAS tool). Finally, the dataset also contains information about whether the defendant did actually recidivate or not.\n",
    "\n",
    "The COMPAS score uses answers to 137 questions to assign a risk score to defendants -- essentially a probability of re-arrest. The actual output is two-fold: a risk rating of 1-10 and a \"low\", \"medium\", or \"high\" risk label.\n",
    "\n",
    "Link to dataset: https://github.com/propublica/compas-analysis\n",
    "\n",
    "The file we will analyze is: compas-scores-two-years.csv\n",
    "\n",
    "Link to the ProPublica article:\n",
    "\n",
    "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
    "\n",
    "\n",
    "## Project Background and Goals\n",
    "\n",
    "- The COMPAS scores have been shown to have biases against certain racial groups. Analyze the dataset to highlight these biases.  \n",
    "\n",
    "- Based on the features in the COMPAS dataset, train classifiers to predict who will re-offend (hint: no need to use all features, just the ones you find relevant).  Study if your classifiers are more or less fair than the COMPAS classifier. \n",
    "\n",
    "- Build a fair classifier. Is excluding the race from the feature set enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fair Re-Offend Predictor\n",
    "\n",
    "by Steve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audit comments will be made in commented code cells, to distinguish from Steve's own writing and code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "First load the data from the ProPublica repo:\n",
    "https://github.com/propublica/compas-analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>10996</td>\n",
       "      <td>steven butler</td>\n",
       "      <td>steven</td>\n",
       "      <td>butler</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-07-17</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>10997</td>\n",
       "      <td>malcolm simmons</td>\n",
       "      <td>malcolm</td>\n",
       "      <td>simmons</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-03-25</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>10999</td>\n",
       "      <td>winston gregory</td>\n",
       "      <td>winston</td>\n",
       "      <td>gregory</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1958-10-01</td>\n",
       "      <td>57</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>11000</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>farrah</td>\n",
       "      <td>jean</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-11-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>11001</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>florencia</td>\n",
       "      <td>sanmartin</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>Female</td>\n",
       "      <td>1992-12-18</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7214 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 name      first         last  \\\n",
       "0         1     miguel hernandez     miguel    hernandez   \n",
       "1         3          kevon dixon      kevon        dixon   \n",
       "2         4             ed philo         ed        philo   \n",
       "3         5          marcu brown      marcu        brown   \n",
       "4         6   bouthy pierrelouis     bouthy  pierrelouis   \n",
       "...     ...                  ...        ...          ...   \n",
       "7209  10996        steven butler     steven       butler   \n",
       "7210  10997      malcolm simmons    malcolm      simmons   \n",
       "7211  10999      winston gregory    winston      gregory   \n",
       "7212  11000          farrah jean     farrah         jean   \n",
       "7213  11001  florencia sanmartin  florencia    sanmartin   \n",
       "\n",
       "     compas_screening_date     sex         dob  age          age_cat  \\\n",
       "0               2013-08-14    Male  1947-04-18   69  Greater than 45   \n",
       "1               2013-01-27    Male  1982-01-22   34          25 - 45   \n",
       "2               2013-04-14    Male  1991-05-14   24     Less than 25   \n",
       "3               2013-01-13    Male  1993-01-21   23     Less than 25   \n",
       "4               2013-03-26    Male  1973-01-22   43          25 - 45   \n",
       "...                    ...     ...         ...  ...              ...   \n",
       "7209            2013-11-23    Male  1992-07-17   23     Less than 25   \n",
       "7210            2014-02-01    Male  1993-03-25   23     Less than 25   \n",
       "7211            2014-01-14    Male  1958-10-01   57  Greater than 45   \n",
       "7212            2014-03-09  Female  1982-11-17   33          25 - 45   \n",
       "7213            2014-06-30  Female  1992-12-18   23     Less than 25   \n",
       "\n",
       "                  race  ...  v_decile_score  v_score_text  v_screening_date  \\\n",
       "0                Other  ...               1           Low        2013-08-14   \n",
       "1     African-American  ...               1           Low        2013-01-27   \n",
       "2     African-American  ...               3           Low        2013-04-14   \n",
       "3     African-American  ...               6        Medium        2013-01-13   \n",
       "4                Other  ...               1           Low        2013-03-26   \n",
       "...                ...  ...             ...           ...               ...   \n",
       "7209  African-American  ...               5        Medium        2013-11-23   \n",
       "7210  African-American  ...               5        Medium        2014-02-01   \n",
       "7211             Other  ...               1           Low        2014-01-14   \n",
       "7212  African-American  ...               2           Low        2014-03-09   \n",
       "7213          Hispanic  ...               4           Low        2014-06-30   \n",
       "\n",
       "      in_custody  out_custody  priors_count.1 start   end event two_year_recid  \n",
       "0     2014-07-07   2014-07-14               0     0   327     0              0  \n",
       "1     2013-01-26   2013-02-05               0     9   159     1              1  \n",
       "2     2013-06-16   2013-06-16               4     0    63     0              1  \n",
       "3            NaN          NaN               1     0  1174     0              0  \n",
       "4            NaN          NaN               2     0  1102     0              0  \n",
       "...          ...          ...             ...   ...   ...   ...            ...  \n",
       "7209  2013-11-22   2013-11-24               0     1   860     0              0  \n",
       "7210  2014-01-31   2014-02-02               0     1   790     0              0  \n",
       "7211  2014-01-13   2014-01-14               0     0   808     0              0  \n",
       "7212  2014-03-08   2014-03-09               3     0   754     0              0  \n",
       "7213  2015-03-15   2015-03-15               2     0   258     0              1  \n",
       "\n",
       "[7214 rows x 53 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "I got rid of difficult columns and then turned categorical features into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
       "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
       "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
       "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
       "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
       "       'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id', 'sex', 'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
    "       'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', \n",
    "       'is_recid', 'is_violent_recid', 'decile_score.1', 'v_decile_score',\n",
    "       'two_year_recid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of the kept columns, several groups seem redundant and prone to cause overfitting:\n",
    "#   'decile_score', 'decile_score.1', 'v_decile_score'\n",
    "#   'age', 'age_cat'\n",
    "#   'is_recid', 'is_violent_recid', 'two_year_recid'\n",
    "\n",
    "# Inclusion of the COMPAS score itself ('decile_score' etc) conflicts with assignment goal:\n",
    "#    \"Study if your classifiers are more or less fair than the COMPAS classifier.\"\n",
    "\n",
    "# 'is_recid', 'is_violent_recid' closely related to target feature 'two_year_recid';\n",
    "# model may just fit to these without finding patterns in other features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "sex                 0\n",
       "age                 0\n",
       "age_cat             0\n",
       "race                0\n",
       "juv_fel_count       0\n",
       "decile_score        0\n",
       "juv_misd_count      0\n",
       "juv_other_count     0\n",
       "priors_count        0\n",
       "c_charge_degree     0\n",
       "is_recid            0\n",
       "is_violent_recid    0\n",
       "decile_score.1      0\n",
       "v_decile_score      0\n",
       "two_year_recid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying nulls is a good first step of data cleaning, but why drop nulls when there are none?\n",
    "# Not a problem but possible sign of poor understanding of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = ['sex','age_cat','race','c_charge_degree'] \n",
    "\n",
    "df = pd.get_dummies(df, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('two_year_recid', axis=1)\n",
    "y = df['two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'is_recid' would be the appropriate target for a model predicting recidivism generally,\n",
    "# although 'is_violent_recid' and 'two_year_recid' are each appropriate for more specific analysis.\n",
    "\n",
    "# The starting dataframe was simply named 'df' and all modifications were done in-place; this is sufficient\n",
    "# but could lead to confusion in more complex analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'juv_fel_count', 'decile_score', 'juv_misd_count',\n",
       "       'juv_other_count', 'priors_count', 'is_recid', 'is_violent_recid',\n",
       "       'decile_score.1', 'v_decile_score', 'sex_Female', 'sex_Male',\n",
       "       'age_cat_25 - 45', 'age_cat_Greater than 45', 'age_cat_Less than 25',\n",
       "       'race_African-American', 'race_Asian', 'race_Caucasian',\n",
       "       'race_Hispanic', 'race_Native American', 'race_Other',\n",
       "       'c_charge_degree_F', 'c_charge_degree_M'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at dummy encoded columns for audit\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encoding the 'sex' and 'c_charge_degree' columns has created redundancies from binary source columns:\n",
    "# 'sex_Female', 'sex_Male'\n",
    "# 'c_charge_degree_F', 'c_charge_degree_M'\n",
    "# these could again lead to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "I picked an SVC because I like them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the SVM classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the confusion matrix\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC's use non-linear functions in high dimensional decision space to set decision function, \n",
    "# which makes interperetaion of the relationship between individual features and the decision boundary challenging.\n",
    "# As this exercise is about analyzing how individual features may affect model bias, \n",
    "# an SVC was not an ideal model choice.\n",
    "\n",
    "# Logistic Regression, Random Forest, XGBoost might be better options for interpretability.\n",
    "\n",
    "# Again, choosing a model \"because I like them\" does not demonstrate understanding of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "I checked accuracy and did a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9611973392461197\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[951,  69],\n",
       "       [  1, 783]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "\n",
    "This is a very good and fair model because it is very accurate and predicts very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"it is very accurate and predicts very well\" technically correct but does not address assignment goals: \n",
    "#   \"Study if your classifiers are more or less fair than the COMPAS classifier.\"\n",
    "#   \"Build a fair classifier. Is excluding the race from the feature set enough?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Your Turn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations to Improve the Model and Reduce Bias\n",
    "\n",
    "`The simplest method to reduce racial bias in the model would be to drop the 'race' column.  `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Bias\n",
    "\n",
    "Using a method of your choosing retrieve feature importance for Steve's model\n",
    "\n",
    "Compare predictions between `African-American` and `Caucasian` using a Confusion Matrix or any other tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_recid: 0.45221729490022167\n",
      "age: 0.002383592017738345\n",
      "priors_count: 0.0010532150776052852\n",
      "is_violent_recid: -5.543237250554833e-05\n",
      "v_decile_score: -5.543237250554833e-05\n",
      "sex_Female: 0.0\n",
      "juv_fel_count: 0.0\n",
      "decile_score: 0.0\n",
      "juv_misd_count: 0.0\n",
      "juv_other_count: 0.0\n",
      "decile_score.1: 0.0\n",
      "c_charge_degree_M: 0.0\n",
      "c_charge_degree_F: 0.0\n",
      "age_cat_25 - 45: 0.0\n",
      "age_cat_Greater than 45: 0.0\n",
      "age_cat_Less than 25: 0.0\n",
      "race_African-American: 0.0\n",
      "race_Asian: 0.0\n",
      "race_Caucasian: 0.0\n",
      "race_Hispanic: 0.0\n",
      "race_Native American: 0.0\n",
      "race_Other: 0.0\n",
      "sex_Male: 0.0\n"
     ]
    }
   ],
   "source": [
    "# SVC is non-linear, use permutation_importance to assign feature importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "\n",
    "# Get names of columns\n",
    "feature_names = X_test.columns\n",
    "\n",
    "# Calculate permutation importance (clf is Steve's SVC model in provided code above)\n",
    "result = permutation_importance(clf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "# Use argsort to sort importances by the absolute value\n",
    "sorted_indices = np.argsort(np.abs(result.importances_mean))\n",
    "\n",
    "# Print feature names and their importance values sorted by importance\n",
    "for idx in sorted_indices[::-1]:  # Reverse the order for descending importance\n",
    "    feature_name = feature_names[idx]\n",
    "    importance_value = result.importances_mean[idx]\n",
    "    print(f\"{feature_name}: {importance_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of model fit for data on Caucasians\n",
      "[[354  15]\n",
      " [  1 231]]\n",
      "Accuracy: 0.9734\n",
      "Precision: 0.9390\n",
      "Recall: 0.9957\n",
      "F1 Score: 0.9665\n",
      "\n",
      "\n",
      "Metrics of model fit for data on African-Americans\n",
      "[[425  47]\n",
      " [  0 473]]\n",
      "Accuracy: 0.9503\n",
      "Precision: 0.9096\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.9527\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrices\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Extract y_test and y_pred for Caucasians and African-Americans (using informal terms for ease of coding)\n",
    "y_test_white = y_test[X_test['race_Caucasian']==1]\n",
    "y_pred_white = y_pred[X_test['race_Caucasian']==1]\n",
    "y_test_black = y_test[X_test['race_African-American']==1]\n",
    "y_pred_black = y_pred[X_test['race_African-American']==1]\n",
    "\n",
    "# Set confusion matrices and scores\n",
    "cm_white = confusion_matrix(y_test_white, y_pred_white)\n",
    "accuracy_white = accuracy_score(y_test_white, y_pred_white)\n",
    "precision_white = precision_score(y_test_white, y_pred_white)\n",
    "recall_white = recall_score(y_test_white, y_pred_white)\n",
    "f1_white = f1_score(y_test_white, y_pred_white)\n",
    "\n",
    "cm_black = confusion_matrix(y_test_black, y_pred_black)\n",
    "accuracy_black = accuracy_score(y_test_black, y_pred_black)\n",
    "precision_black = precision_score(y_test_black, y_pred_black)\n",
    "recall_black = recall_score(y_test_black, y_pred_black)\n",
    "f1_black = f1_score(y_test_black, y_pred_black)\n",
    "\n",
    "# Print cm's and scores\n",
    "print('Metrics of model fit for data on Caucasians')\n",
    "print(cm_white)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_white))\n",
    "print(\"Precision: {:.4f}\".format(precision_white))\n",
    "print(\"Recall: {:.4f}\".format(recall_white))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_white))\n",
    "\n",
    "print('\\n')\n",
    "print('Metrics of model fit for data on African-Americans')\n",
    "print(cm_black)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_black))\n",
    "print(\"Precision: {:.4f}\".format(precision_black))\n",
    "print(\"Recall: {:.4f}\".format(recall_black))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_black))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results \n",
    "The redundant features:\n",
    "is_recid, is_violent_recid \n",
    "decile_score, v_decile_score\n",
    "Were all among the most important features of the model. The recidivism measures are closely related to the target feature and may act as a \"cheat sheet\" for the model, inflating its accuracy. The model may be overfit to decile score, which are themselves results of the scoring process we want to analyze. Given the relative importance of these features, it's hard to assign a level of \"fairness\" to how it treats the demographic features.\n",
    "\n",
    "The use of an SVC model presented me with technical difficultes getting TensorFlow Fairness Indicators to run on a non-linear model.\n",
    "\n",
    "Precision is slightly higher for Caucasians while recall is slightly higher (at 100%) for African-Americans. This indicates that the model is indeed better at avoiding false positives for Caucasians, and at avoiding false negatives for African-Americans.\n",
    "Rephrased more directly, the model can be seen as biased to predicting recidivism among African Americans. However, given the very high model scores for both groups, this may not be a significant or meaningful finding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve the Model\n",
    "\n",
    "Implement some/all of your suggestions to make Steve's model better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggestions for improvement:\n",
    "#   Set 'is_recid' as target, drop 'two_year_recid' and 'is_violent_recid'\n",
    "#   Create 'custody_duration' from 'custody_in' and 'custody_out' dates\n",
    "#   Drop 'decile_score', 'decile_score.1', 'v_decile_score' to not have COMPAS score itself affect model\n",
    "#   Drop age_cat, after dummy encoding drop 'c_charge_degree_F', 'sex_Female' \n",
    "#   Use Logistic Regression model to start, then perhpas other models more interperetable than SVC\n",
    "#   Use TensorFlow Fairness Indicators to analyze model and make adjustments\n",
    "#   Create second model using COMPAS score feature(s) and do same fairness analysis for comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import source data\n",
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'\n",
    "source_df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
       "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
       "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
       "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
       "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
       "       'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model w/o COMPAS features\n",
    "# Retain only demographic columns, drop COMPAS scores and \n",
    "demographic_df = source_df[['id', 'sex', 'age', 'race', 'juv_fel_count', \n",
    "       'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', \n",
    "       'is_recid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'id' as index\n",
    "demographic_df = demographic_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
       "       'priors_count', 'is_recid', 'sex_Female', 'sex_Male',\n",
       "       'race_African-American', 'race_Asian', 'race_Caucasian',\n",
       "       'race_Hispanic', 'race_Native American', 'race_Other',\n",
       "       'c_charge_degree_F', 'c_charge_degree_M'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy encode categorical features \n",
    "dummy_cols = ['sex','race','c_charge_degree'] \n",
    "\n",
    "demographic_df = pd.get_dummies(demographic_df, columns=dummy_cols)\n",
    "demographic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant dummy features\n",
    "drop_dummies = ['sex_Female', 'c_charge_degree_F']\n",
    "demographic_df = demographic_df.drop(columns=drop_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'is_recid' as target\n",
    "X = demographic_df.drop('is_recid', axis=1)\n",
    "y = demographic_df['is_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000) # increasing iterations suggested by python warning\n",
    "\n",
    "# Train the classifier\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metrics\n",
      "[[479 428]\n",
      " [473 424]]\n",
      "Accuracy: 0.5006\n",
      "Precision: 0.4977\n",
      "Recall: 0.4727\n",
      "F1 Score: 0.4848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print cm and scores\n",
    "print('Model metrics')\n",
    "print(cm)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex_Male: 0.352\n",
      "juv_fel_count: 0.238\n",
      "race_Native American: 0.219\n",
      "race_African-American: 0.205\n",
      "c_charge_degree_M: -0.200\n",
      "priors_count: 0.162\n",
      "juv_other_count: 0.145\n",
      "race_Hispanic: -0.109\n",
      "race_Caucasian: 0.077\n",
      "race_Other: -0.045\n",
      "age: -0.042\n",
      "race_Asian: 0.036\n",
      "juv_misd_count: 0.024\n"
     ]
    }
   ],
   "source": [
    "# Retrieve feature coeeficients for feature importance\n",
    "# Access the coefficients and feature names\n",
    "coefficients = model.coef_[0]\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Use argsort to sort coefficients by the absolute value\n",
    "sorted_indices = np.argsort(np.abs(coefficients))\n",
    "\n",
    "# Print feature names and their coefficients sorted by absolute value\n",
    "for idx in sorted_indices[::-1]:  # Reverse the order for descending absolute importance\n",
    "    feature_name = feature_names[idx]\n",
    "    coefficient_value = coefficients[idx]\n",
    "    print(f\"{feature_name}: {coefficient_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of model fit for data on Caucasians\n",
      "[[183 152]\n",
      " [138 135]]\n",
      "Accuracy: 0.5230\n",
      "Precision: 0.4704\n",
      "Recall: 0.4945\n",
      "F1 Score: 0.4821\n",
      "\n",
      "\n",
      "Metrics of model fit for data on African-Americans\n",
      "[[218 206]\n",
      " [286 249]]\n",
      "Accuracy: 0.4870\n",
      "Precision: 0.5473\n",
      "Recall: 0.4654\n",
      "F1 Score: 0.5030\n"
     ]
    }
   ],
   "source": [
    "# Extract y_test and y_pred for Caucasians and African-Americans (using informal terms for ease of coding)\n",
    "y_test_white = y_test[X_test['race_Caucasian']==1]\n",
    "y_pred_white = y_pred[X_test['race_Caucasian']==1]\n",
    "y_test_black = y_test[X_test['race_African-American']==1]\n",
    "y_pred_black = y_pred[X_test['race_African-American']==1]\n",
    "\n",
    "# Set confusion matrices and scores\n",
    "cm_white = confusion_matrix(y_test_white, y_pred_white)\n",
    "accuracy_white = accuracy_score(y_test_white, y_pred_white)\n",
    "precision_white = precision_score(y_test_white, y_pred_white)\n",
    "recall_white = recall_score(y_test_white, y_pred_white)\n",
    "f1_white = f1_score(y_test_white, y_pred_white)\n",
    "\n",
    "cm_black = confusion_matrix(y_test_black, y_pred_black)\n",
    "accuracy_black = accuracy_score(y_test_black, y_pred_black)\n",
    "precision_black = precision_score(y_test_black, y_pred_black)\n",
    "recall_black = recall_score(y_test_black, y_pred_black)\n",
    "f1_black = f1_score(y_test_black, y_pred_black)\n",
    "\n",
    "# Print cm's and scores\n",
    "print('Metrics of model fit for data on Caucasians')\n",
    "print(cm_white)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_white))\n",
    "print(\"Precision: {:.4f}\".format(precision_white))\n",
    "print(\"Recall: {:.4f}\".format(recall_white))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_white))\n",
    "\n",
    "print('\\n')\n",
    "print('Metrics of model fit for data on African-Americans')\n",
    "print(cm_black)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_black))\n",
    "print(\"Precision: {:.4f}\".format(precision_black))\n",
    "print(\"Recall: {:.4f}\".format(recall_black))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_black))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating w/o COMPAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat with inclusion of COMPAS score data\n",
    "compas_df = source_df[['id', 'sex', 'age', 'race', 'juv_fel_count', \n",
    "       'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', \n",
    "       'is_recid', 'decile_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_df = compas_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encode categorical features \n",
    "dummy_cols = ['sex','race','c_charge_degree'] \n",
    "\n",
    "compas_df = pd.get_dummies(compas_df, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant dummy features\n",
    "drop_dummies = ['sex_Female', 'c_charge_degree_F']\n",
    "compas_df = compas_df.drop(columns=drop_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'is_recid' as target\n",
    "X = compas_df.drop('is_recid', axis=1)\n",
    "y = compas_df['is_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/anaconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Logistic Regression classifier\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the classifier\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model metrics for Logistic Regression w/ COMPAS score\n",
      "[[521 444]\n",
      " [431 408]]\n",
      "Accuracy: 0.5150\n",
      "Precision: 0.4789\n",
      "Recall: 0.4863\n",
      "F1 Score: 0.4826\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print cm and scores\n",
    "print('Model metrics for Logistic Regression w/ COMPAS score')\n",
    "print(cm)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex_Male: 0.360\n",
      "juv_other_count: 0.241\n",
      "race_Hispanic: -0.164\n",
      "decile_score: 0.146\n",
      "juv_fel_count: 0.144\n",
      "race_Other: -0.131\n",
      "priors_count: 0.116\n",
      "c_charge_degree_M: -0.088\n",
      "race_Native American: 0.072\n",
      "race_Asian: -0.064\n",
      "juv_misd_count: -0.042\n",
      "race_African-American: 0.041\n",
      "age: -0.032\n",
      "race_Caucasian: -0.001\n"
     ]
    }
   ],
   "source": [
    "# Retrieve feature coeeficients for feature importance\n",
    "# Access the coefficients and feature names\n",
    "coefficients = model.coef_[0]\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Use argsort to sort coefficients by the absolute value\n",
    "sorted_indices = np.argsort(np.abs(coefficients))\n",
    "\n",
    "# Print feature names and their coefficients sorted by absolute value\n",
    "for idx in sorted_indices[::-1]:  # Reverse the order for descending absolute importance\n",
    "    feature_name = feature_names[idx]\n",
    "    coefficient_value = coefficients[idx]\n",
    "    print(f\"{feature_name}: {coefficient_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of model fit for data on Caucasians\n",
      "[[184 175]\n",
      " [132 133]]\n",
      "Accuracy: 0.5080\n",
      "Precision: 0.4318\n",
      "Recall: 0.5019\n",
      "F1 Score: 0.4642\n",
      "\n",
      "\n",
      "Metrics of model fit for data on African-Americans\n",
      "[[253 189]\n",
      " [240 225]]\n",
      "Accuracy: 0.5270\n",
      "Precision: 0.5435\n",
      "Recall: 0.4839\n",
      "F1 Score: 0.5119\n"
     ]
    }
   ],
   "source": [
    "# Extract y_test and y_pred for Caucasians and African-Americans (using informal terms for ease of coding)\n",
    "y_test_white = y_test[X_test['race_Caucasian']==1]\n",
    "y_pred_white = y_pred[X_test['race_Caucasian']==1]\n",
    "y_test_black = y_test[X_test['race_African-American']==1]\n",
    "y_pred_black = y_pred[X_test['race_African-American']==1]\n",
    "\n",
    "# Set confusion matrices and scores\n",
    "cm_white = confusion_matrix(y_test_white, y_pred_white)\n",
    "accuracy_white = accuracy_score(y_test_white, y_pred_white)\n",
    "precision_white = precision_score(y_test_white, y_pred_white)\n",
    "recall_white = recall_score(y_test_white, y_pred_white)\n",
    "f1_white = f1_score(y_test_white, y_pred_white)\n",
    "\n",
    "cm_black = confusion_matrix(y_test_black, y_pred_black)\n",
    "accuracy_black = accuracy_score(y_test_black, y_pred_black)\n",
    "precision_black = precision_score(y_test_black, y_pred_black)\n",
    "recall_black = recall_score(y_test_black, y_pred_black)\n",
    "f1_black = f1_score(y_test_black, y_pred_black)\n",
    "\n",
    "# Print cm's and scores\n",
    "print('Metrics of model fit for data on Caucasians')\n",
    "print(cm_white)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_white))\n",
    "print(\"Precision: {:.4f}\".format(precision_white))\n",
    "print(\"Recall: {:.4f}\".format(recall_white))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_white))\n",
    "\n",
    "print('\\n')\n",
    "print('Metrics of model fit for data on African-Americans')\n",
    "print(cm_black)\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_black))\n",
    "print(\"Precision: {:.4f}\".format(precision_black))\n",
    "print(\"Recall: {:.4f}\".format(recall_black))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_black))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
